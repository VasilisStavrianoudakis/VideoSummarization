{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from typing import List, Any, Tuple, Optional, Union\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "from torchvision import models, transforms\n",
    "import av\n",
    "from yt_dlp import YoutubeDL\n",
    "import numpy as np\n",
    "import torch\n",
    "from moviepy import editor\n",
    "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
    "from pytorchvideo.data.encoded_video import EncodedVideo\n",
    "from transformers import (\n",
    "    VideoMAEForVideoClassification,\n",
    "    VideoMAEImageProcessor,\n",
    "    VideoMAEModel,\n",
    ")\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_videos_to = \"data\"\n",
    "start_at_sec = 5\n",
    "window = 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Helper Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class HighlightsFinder:\n",
    "    def __init__(self, batch_size: int = 32) -> None:\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.batch_size = batch_size\n",
    "        model = models.resnet18(pretrained=True)\n",
    "        self.model = torch.nn.Sequential(*(list(model.children())[:-1])).to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "    def _get_transformations(self, will_be_saved: bool) -> List[Any]:\n",
    "        transformations = [\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "        if will_be_saved:\n",
    "            transformations.append(transforms.ToPILImage())\n",
    "        return transformations\n",
    "\n",
    "    def _preprocess_image(\n",
    "        self, image: Image.Image, will_be_saved: bool = False\n",
    "    ) -> Union[torch.Tensor, Image.Image]:\n",
    "        transformations = self._get_transformations(will_be_saved=will_be_saved)\n",
    "\n",
    "        transform = transforms.Compose(transformations)\n",
    "        image = transform(image)\n",
    "        if will_be_saved:\n",
    "            return image\n",
    "\n",
    "        image = image.unsqueeze(0)\n",
    "        # print(image.shape)\n",
    "        return image\n",
    "\n",
    "    def _chunks(self, lst, n):\n",
    "        \"\"\"\n",
    "        Yield successive n-sized chunks from lst.\n",
    "        \"\"\"\n",
    "        for i in range(0, len(lst), n):\n",
    "            yield lst[i : i + n]\n",
    "\n",
    "    def _create_feature_vectors(self, file_paths: List[str]) -> np.ndarray:\n",
    "        features = None\n",
    "        for file_paths_chunk in self._chunks(file_paths, n=self.batch_size):\n",
    "            # Get the data for this batch.\n",
    "            imgs = [Image.open(img).convert(\"RGB\") for img in file_paths_chunk]\n",
    "            imgs = [self._preprocess_image(img) for img in imgs]\n",
    "            imgs = torch.cat(imgs, dim=0).to(self.device)\n",
    "\n",
    "            # Convert them to features.\n",
    "            with torch.no_grad():\n",
    "                f = self.model(imgs)\n",
    "\n",
    "            if features is None:\n",
    "                features = f.clone()\n",
    "            else:\n",
    "                features = torch.cat((features, f), dim=0)\n",
    "\n",
    "        features = features.squeeze(dim=-1)\n",
    "        features = features.squeeze(dim=-1)\n",
    "        features = features.cpu().detach().numpy()\n",
    "        return features\n",
    "\n",
    "    def find_highlights(self, frames_path: str, num_highlights: int) -> List[str]:\n",
    "        file_paths = glob.glob(os.path.join(frames_path, \"*.jpg\"))\n",
    "        features = self._create_feature_vectors(file_paths=file_paths)\n",
    "        distances = cosine_distances(features, features)\n",
    "        del features\n",
    "        median_distances = np.median(distances, axis=1)\n",
    "        del distances\n",
    "        assert median_distances.shape[0] == len(file_paths)\n",
    "        idx = np.argsort(median_distances)[-num_highlights:]\n",
    "\n",
    "        highlights = np.array(file_paths)[idx].tolist()\n",
    "        return highlights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_path: str, images_folder: str, start_at_sec: int = 5, window: int = 10):\n",
    "    os.makedirs(images_folder, exist_ok=True)\n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "    success, image = vidcap.read()\n",
    "    success = True\n",
    "    while success:\n",
    "        vidcap.set(cv2.CAP_PROP_POS_MSEC, (start_at_sec * 1000))  # One frame per second.\n",
    "        success, image = vidcap.read()\n",
    "        # print(\"Read a new frame: \", success)\n",
    "        if success:\n",
    "            cv2.imwrite(os.path.join(images_folder, f\"sec_{start_at_sec}.jpg\"), image)  # save frame as JPEG file.\n",
    "        start_at_sec += window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_timestamps(timestamps: List[Tuple]) -> List[Tuple]:\n",
    "    merged_timestamps = []\n",
    "    # timestamps.sort(key=lambda x: x[0])  # Sort the timestamps based on start time\n",
    "\n",
    "    for timestamp in timestamps:\n",
    "        if merged_timestamps and timestamp[0] == merged_timestamps[-1][1]:\n",
    "            merged_timestamps[-1] = (merged_timestamps[-1][0], timestamp[1])  # Extend the previous timestamp\n",
    "        else:\n",
    "            merged_timestamps.append(timestamp)  # Add a new timestamp\n",
    "\n",
    "    return merged_timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 5), (10, 120)]\n"
     ]
    }
   ],
   "source": [
    "# t = [(0, 5), (10, 20), (20, 30), (30, 40), (40, 120)]\n",
    "# print(merge_timestamps(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_paths_to_timestamps(file_paths: List[str], window: int) -> List[Tuple]:\n",
    "    paths = [os.path.basename(path) for path in file_paths]\n",
    "    paths = [Path(path).stem for path in file_paths]\n",
    "    times = [int(path.replace(\"sec_\", \"\")) for path in paths]\n",
    "    times = list(sorted(times))\n",
    "    timestamps = [(int(time - window / 2), int(time + window / 2)) for time in times]\n",
    "    timestamps = merge_timestamps(timestamps=timestamps)\n",
    "    return timestamps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Download Videos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube:tab] Extracting URL: https://www.youtube.com/watch?v=SvV6aUki6LU&list=PLCGIzmTE4d0iCqSmha1X7F-_AqB3jjo26&index=7&ab_channel=FIFA\n",
      "[youtube:tab] Downloading just the video SvV6aUki6LU because of --no-playlist\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=SvV6aUki6LU\n",
      "[youtube] SvV6aUki6LU: Downloading webpage\n",
      "[youtube] SvV6aUki6LU: Downloading ios player API JSON\n",
      "[youtube] SvV6aUki6LU: Downloading android player API JSON\n",
      "[youtube] SvV6aUki6LU: Downloading m3u8 information\n",
      "[info] SvV6aUki6LU: Downloading 1 format(s): 614+140\n",
      "[hlsnative] Downloading m3u8 manifest\n",
      "[hlsnative] Total fragments: 1207\n",
      "[download] Destination: data\\SvV6aUki6LU.f614.mp4\n",
      "[download] 100% of    1.70GiB in 00:04:57 at 5.84MiB/s                        \n",
      "[download] Destination: data\\SvV6aUki6LU.f140.m4a\n",
      "[download] 100% of   94.38MiB in 00:00:08 at 10.59MiB/s    \n",
      "[Merger] Merging formats into \"data\\SvV6aUki6LU.mp4\"\n",
      "Deleting original file data\\SvV6aUki6LU.f140.m4a (pass -k to keep)\n",
      "Deleting original file data\\SvV6aUki6LU.f614.mp4 (pass -k to keep)\n"
     ]
    }
   ],
   "source": [
    "links = [\n",
    "    # \"https://www.youtube.com/watch?v=d0r0vzvqeoc&ab_channel=LubenTV\",\n",
    "    \"https://www.youtube.com/watch?v=SvV6aUki6LU&list=PLCGIzmTE4d0iCqSmha1X7F-_AqB3jjo26&index=7&ab_channel=FIFA\",\n",
    "]\n",
    "\n",
    "ydl_opts = {\"noplaylist\": True, \"outtmpl\": os.path.join(save_videos_to, \"%(id)s\"), \"format\": \"bv*[ext=mp4]+ba[ext=m4a]/b[ext=mp4] / bv*+ba/b\"}\n",
    "\n",
    "with YoutubeDL(ydl_opts) as ydl:\n",
    "    ydl.download(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Extract frames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\d0r0vzvqeoc\n",
      "data\\d0r0vzvqeoc_summary\n",
      "data\\SvV6aUki6LU\n"
     ]
    }
   ],
   "source": [
    "# videos_path = \"test_video.mp4\"\n",
    "for video_path in glob.glob(os.path.join(save_videos_to, \"*.mp4\")):\n",
    "  if \"summary\" in video_path:\n",
    "    continue\n",
    "  clips_output_path = os.path.splitext(video_path)[0]\n",
    "  print(clips_output_path)\n",
    "\n",
    "  extract_frames(video_path=video_path, images_folder=clips_output_path, start_at_sec=start_at_sec, window=window)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Extract audio from a clip**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in audio.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "#Load the Video\n",
    "video = editor.VideoFileClip(\"test_video.mp4\")\n",
    "\n",
    "#Extract the Audio\n",
    "audio = video.audio\n",
    "\n",
    "#Export the Audio\n",
    "audio.write_audiofile(\"audio.mp3\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Extract highlights from frames video**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = HighlightsFinder(batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_output_paths = [f.path for f in os.scandir(save_videos_to) if f.is_dir() and \"ipynb_checkpoints\" not in f.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 15, 25, 35, 115]\n",
      "[(0, 40), (110, 120)]\n",
      "[(0, 40), (110, 120)]\n",
      "Moviepy - Building video data\\d0r0vzvqeoc_summary.mp4.\n",
      "MoviePy - Writing audio in d0r0vzvqeoc_summaryTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video data\\d0r0vzvqeoc_summary.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready data\\d0r0vzvqeoc_summary.mp4\n",
      "[835, 1275, 3415, 4605, 5375]\n",
      "[(830, 840), (1270, 1280), (3410, 3420), (4600, 4610), (5370, 5380)]\n",
      "[(830, 840), (1270, 1280), (3410, 3420), (4600, 4610), (5370, 5380)]\n",
      "Moviepy - Building video data\\SvV6aUki6LU_summary.mp4.\n",
      "MoviePy - Writing audio in SvV6aUki6LU_summaryTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video data\\SvV6aUki6LU_summary.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready data\\SvV6aUki6LU_summary.mp4\n"
     ]
    }
   ],
   "source": [
    "for frames_path in frames_output_paths:\n",
    "    # print(frames_path)\n",
    "    highlights = hf.find_highlights(frames_path=frames_path, num_highlights=5)\n",
    "    timestamps = convert_paths_to_timestamps(file_paths=highlights, window=window)\n",
    "    video = editor.VideoFileClip(frames_path + \".mp4\")\n",
    "    clips = []\n",
    "    for start_time , end_time in timestamps:\n",
    "        clip = video.subclip(start_time, end_time)\n",
    "        clips.append(clip)\n",
    "    \n",
    "    final = editor.concatenate_videoclips(clips)\n",
    "    final.write_videofile(frames_path + \"_summary.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "videosummarization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
